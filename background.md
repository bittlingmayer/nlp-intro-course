## Day 1: Background

### Lecture 1

What problems are considered NLP, what the motivation is, why language is hard, why humans are good at it, what structure and mathematical properties language has, why rules-based doesn't scale, what is solved, what is unsolved, what is unsolvableâ€¦

Beyond English: multi-lingual problems.

Slides [coming soon]

### Lecture 2
We cover the language of language:

> anaphora, BLEU, canonicalisation, grammars, lemmatisation, n-grams, parallel corpora, segmentation, tokenisation, Zipf's law...

Slides [coming soon]

### Lab:
Increase the accuracy of Peter Norvig's classic [spelling corrector in half a page of code](http://norvig.com/spell-correct.html) without hurting performance too much.

Change the cost function, use context, use the subword level, preprocess, add more data...

### More

Watch [Lecture 1 from Stanford's *Natural Language Processing with Deep Learning*](https://www.youtube.com/watch?v=OQQ-W_63UgQ)  

Understand the title of each chapter of [Foundations of Statistical Natural Language Processing](https://nlp.stanford.edu/fsnlp/)  

Try to understand [how `str` works in python 3](https://docs.python.org/3/howto/unicode.html#python-s-unicode-support)  

Play with the [displaCy](https://demos.explosion.ai/displacy/) parsing visualisation

Read [Norvig vs Chomsky](http://norvig.com/chomsky.html) with a good drink
