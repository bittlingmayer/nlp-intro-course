
# 2. Deep Learning

## Lecture 1
Motivation for deep learning, trade-offs of preprocessing, autoencoders and word embeddings, doc vectors vs word vectors vs char vectors

[Slides](https://docs.google.com/presentation/d/1eV0nCqNphoZJ3v7bulyamGe4CepF6sDN9-xXuBnR6qc/edit?usp=sharing)

## Lecture 2
Generating and augmenting data for speech recognition, translit, and grammar correction

[Slides](https://docs.google.com/presentation/d/1rZYsCpMOop0z5oAvslWSw6l5PYHkjDY4ClD_n2vgaeg/edit?usp=sharing)

## Lab
spaCy

## More
Watch the second part of [Lecture 1 from Stanford's *Natural Language Processing with Deep Learning*](https://www.youtube.com/watch?v=OQQ-W_63UgQ)  
Read [Manning: *Last Words: Computational Linguistics and Deep Learning*](mitp.nautil.us/article/170/last-words-computational-linguistics-and-deep-learning)  
Watch Hugo LaRochelle's *Neural networks* [10.1](https://www.youtube.com/watch?v=OzZIOiMVUyM&list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH&index=79)... [10.6](https://www.youtube.com/watch?v=FoDz01QNSiY&index=84&list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH)

https://explosion.ai/blog/deep-learning-formula-nlp  
https://spacy.io/docs/usage/word-vectors-similarities

https://aiexperiments.withgoogle.com/visualizing-high-dimensional-space  
http://projector.tensorflow.org

## Questions

In which area of NLP has deep learning had the most impact as of mid-2017?

Should we lowercase and remove punctuation from our dataset before training?

What is Google SentencePiece for?

How many rows of data do we need for tasks like spelling correction or translation?
